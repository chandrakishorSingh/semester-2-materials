{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MIT2021117_DT_Program_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgVFk7Z_jLVx",
        "outputId": "b39f70c6-edfc-42f7-da24-d3bb4a1ad816"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['capacity=5', 'maintenance=high', '[prediction=no]']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "\n",
        "# Decision Tree Node definition\n",
        "class DTNode:\n",
        "    # initialize node\n",
        "    def __init__(self, node_type=\"label\", label=None, entropy=None, feature_name=None, children=None, parent=None):\n",
        "        self.node_type = node_type\n",
        "        self.label = label\n",
        "        self.entropy = entropy\n",
        "        self.feature_name = feature_name\n",
        "        self.children = children\n",
        "        self.parent = parent\n",
        "\n",
        "\n",
        "# Decision Tree definition\n",
        "class DT:\n",
        "    # initialize decision tree\n",
        "    def __init__(self, data, target_feature):\n",
        "        self.data = data\n",
        "        self.target_feature = target_feature\n",
        "        self.features = self._get_features()\n",
        "\n",
        "        # get the input features by removing the target feature from feature list\n",
        "        remaining_features = self.features.copy()\n",
        "        del remaining_features[self.target_feature]\n",
        "\n",
        "        # build the tree\n",
        "        self.root = self._build_tree(self.data.copy(), remaining_features.copy(), None)\n",
        "\n",
        "    # predict the label of a new row/record(other than those present in the dataset)\n",
        "    def predict(self, record):\n",
        "        decision_path = []\n",
        "        node = self.root\n",
        "\n",
        "        # go down the tree until a node of `node_type` having \"label\" is found\n",
        "        while node.node_type != 'label':\n",
        "            decision_path.append(str(node.feature_name) + '=' + str(record[node.feature_name]))\n",
        "            node = node.children[record[node.feature_name]]\n",
        "\n",
        "        decision_path.append(f\"[prediction={node.label}]\")\n",
        "\n",
        "        return decision_path\n",
        "\n",
        "    # finds all the features of the given dataset\n",
        "    def _get_features(self):\n",
        "        features = {}\n",
        "\n",
        "        feature_names = list(self.data.columns)\n",
        "        for feature in feature_names:\n",
        "            features[feature] = set(self.data.get(feature))\n",
        "\n",
        "        return features\n",
        "\n",
        "    # build the decision tree recursively\n",
        "    def _build_tree(self, data, features, parent):\n",
        "        # if feature list is empty then find the most common value of the target variable and create a node with `label` equal to that value\n",
        "        if len(features) == 0:\n",
        "            target_attr_value_list = list(data.get(self.target_feature))\n",
        "            target_attr_value_count = {}\n",
        "            for attr_value in target_attr_value_list:\n",
        "                if attr_value in target_attr_value_count:\n",
        "                    target_attr_value_count[attr_value] = target_attr_value_count[attr_value] + 1\n",
        "                else:\n",
        "                    target_attr_value_count[attr_value] = 1\n",
        "\n",
        "            max_attr_value_count = 0\n",
        "            max_attr = ''\n",
        "            for attr_value in target_attr_value_count:\n",
        "                if max_attr_value_count < target_attr_value_count[attr_value]:\n",
        "                    max_attr_value_count = target_attr_value_count[attr_value]\n",
        "                    max_attr = attr_value\n",
        "\n",
        "            return DTNode(label=max_attr)\n",
        "\n",
        "        # if the value of target variable is same for the current dataset then create a node having `label` value equal to that common value\n",
        "        if len(set(data.get(self.target_feature))) == 1:\n",
        "            return DTNode(label=data.get(self.target_feature).iloc[0])\n",
        "\n",
        "        # otherwise, calculte the entropies of all current features\n",
        "        feature_entropies = {}\n",
        "\n",
        "        for feature_name in features:\n",
        "            attr_entropies = {}\n",
        "            attr_record_count = {}\n",
        "            attrs = features[feature_name]\n",
        "            for attr in attrs:\n",
        "                subset_data = data.loc[data[feature_name] == attr]\n",
        "                attr_entropies[attr] = self._get_entropy(subset_data)\n",
        "                attr_record_count[attr] = len(subset_data)\n",
        "\n",
        "            feature_entropies[feature_name] = sum(\n",
        "                [attr_entropies[attr] * attr_record_count[attr] for attr in attrs]) / sum(\n",
        "                attr_record_count[attr] for attr in attrs)\n",
        "\n",
        "        # get the entropy of parent node\n",
        "        parent_entropy = self._get_entropy(self.data) if parent == None else parent.entropy\n",
        "\n",
        "        # find the information gains of all current features\n",
        "        igs = {feature_name: parent_entropy - feature_entropies[feature_name] for feature_name in features}\n",
        "\n",
        "        # find the feature having maximum information gain\n",
        "        max_ig_feature = ''\n",
        "        max_ig = -1\n",
        "        for feature_name in igs:\n",
        "            if max_ig < igs[feature_name]:\n",
        "                max_ig = igs[feature_name]\n",
        "                max_ig_feature = feature_name\n",
        "\n",
        "        # create a node with that feature\n",
        "        node = DTNode(node_type='internal', entropy=feature_entropies[max_ig_feature], feature_name=max_ig_feature,\n",
        "                      children=None, parent=parent)\n",
        "\n",
        "        # distribute the data according to attr. of chosen feature and assign child nodes and build the tree recursively\n",
        "        children = {}\n",
        "        remaining_features = features.copy()\n",
        "        del remaining_features[max_ig_feature]\n",
        "        for attr in features[max_ig_feature]:\n",
        "            remaining_data = data.copy()\n",
        "            remaining_data = remaining_data.loc[remaining_data[max_ig_feature] == attr]\n",
        "            children[attr] = self._build_tree(remaining_data.copy(), remaining_features.copy(), node)\n",
        "\n",
        "        node.children = children\n",
        "\n",
        "        return node\n",
        "\n",
        "    # finds the entropy of the given sample(data)\n",
        "    def _get_entropy(self, data):\n",
        "        label_counts = {}\n",
        "\n",
        "        for label in data.get(self.target_feature):\n",
        "            if label in label_counts:\n",
        "                label_counts[label] += 1\n",
        "            else:\n",
        "                label_counts[label] = 1\n",
        "\n",
        "        sample_count = sum([label_counts[label] for label in label_counts])\n",
        "        entropy = sum([\n",
        "            (label_counts[label] / sample_count) * math.log((label_counts[label] / sample_count), 2)\n",
        "            if label_counts[label] != 0 else 0 for label in label_counts\n",
        "        ])\n",
        "\n",
        "        return -1 * entropy\n",
        "\n",
        "\n",
        "\n",
        "# load the data\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data.csv')\n",
        "\n",
        "# initialize the tree\n",
        "dt = DT(data, 'profit')\n",
        "\n",
        "# predict the class of a new record\n",
        "print(dt.predict({'price': 'low', 'maintenance': 'high', 'capacity': 5, 'airbag': 'no'}))\n",
        "\n"
      ]
    }
  ]
}