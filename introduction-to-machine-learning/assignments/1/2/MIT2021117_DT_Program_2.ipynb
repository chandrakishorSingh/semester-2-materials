{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MIT2021117_DT_Program_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxS-JAv2ks2R",
        "outputId": "223920b7-9b6b-4cfd-846e-5f87dc0f1cb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['maintenance=high', 'capacity=5', 'price=low', '[prediction=no]']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "\n",
        "# Decision Tree Node definition\n",
        "class DTNode:\n",
        "    # initialize node\n",
        "    def __init__(self, node_type=\"label\", label=None, gini_index=None, feature_name=None, left_attr_collection=None,\n",
        "                 right_attr_collection=None, left=None, right=None):\n",
        "        self.node_type = node_type\n",
        "        self.label = label\n",
        "        self.gini_index = gini_index\n",
        "        self.feature_name = feature_name\n",
        "        self.left_attr_collection = left_attr_collection  # this will be a `list` type\n",
        "        self.right_attr_collection = right_attr_collection\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "\n",
        "# Decision Tree definition\n",
        "class DT:\n",
        "    # initialize decision tree\n",
        "    def __init__(self, data, target_feature):\n",
        "        self.data = data\n",
        "        self.target_feature = target_feature\n",
        "        self.features = self._get_features()\n",
        "\n",
        "        # get the input features by removing the target feature from feature list\n",
        "        remaining_features = self.features.copy()\n",
        "        del remaining_features[self.target_feature]\n",
        "\n",
        "        # build the tree\n",
        "        self.root = self._build_tree(self.data.copy(), remaining_features.copy())\n",
        "\n",
        "    # get all possible combinations of the attrs. of given feature\n",
        "    def _get_feature_attr_sets(self, attrs):\n",
        "        attr_sets = []\n",
        "        set_count = 2 ** (len(attrs) - 1) - 1\n",
        "        for i in range(1, set_count + 1):\n",
        "            attr_set = []\n",
        "            for j in range(len(attrs)):\n",
        "                if (1 << j) & i:\n",
        "                    attr_set.append(attrs[j])\n",
        "            attr_sets.append([attr_set, list(set(attrs) - set(attr_set))])\n",
        "\n",
        "        return attr_sets\n",
        "\n",
        "    # predict the label of a new row/record(other than those present in the dataset)\n",
        "    def predict(self, record):\n",
        "        decision_path = []\n",
        "        node = self.root\n",
        "\n",
        "        # go down the tree until a node of `node_type` having \"label\" is found\n",
        "        while node.node_type != 'label':\n",
        "            decision_path.append(str(node.feature_name) + '=' + str(record[node.feature_name]))\n",
        "            if record[node.feature_name] in node.left_attr_collection:\n",
        "                node = node.left\n",
        "            else:\n",
        "                node = node.right\n",
        "\n",
        "        decision_path.append(f\"[prediction={node.label}]\")\n",
        "\n",
        "        return decision_path\n",
        "\n",
        "    # finds all the features of the given dataset\n",
        "    def _get_features(self):\n",
        "        features = {}\n",
        "\n",
        "        feature_names = list(self.data.columns)\n",
        "        for feature in feature_names:\n",
        "            features[feature] = set(self.data.get(feature))\n",
        "\n",
        "        return features\n",
        "\n",
        "    # build the decision tree recursively\n",
        "    def _build_tree(self, data, features):\n",
        "        # if feature list is empty then find the most common value of the target variable and create a node with `label` equal to that value\n",
        "        if len(features) == 0:\n",
        "            target_attr_value_list = list(data.get(self.target_feature))\n",
        "            target_attr_value_count = {}\n",
        "            for attr_value in target_attr_value_list:\n",
        "                if attr_value in target_attr_value_count:\n",
        "                    target_attr_value_count[attr_value] = target_attr_value_count[attr_value] + 1\n",
        "                else:\n",
        "                    target_attr_value_count[attr_value] = 1\n",
        "\n",
        "            max_attr_value_count = 0\n",
        "            max_attr = ''\n",
        "            for attr_value in target_attr_value_count:\n",
        "                if max_attr_value_count < target_attr_value_count[attr_value]:\n",
        "                    max_attr_value_count = target_attr_value_count[attr_value]\n",
        "                    max_attr = attr_value\n",
        "\n",
        "            return DTNode(label=max_attr)\n",
        "\n",
        "        # if the value of target variable is same for the current dataset then create a node having `label` value equal to that common value\n",
        "        if len(set(data.get(self.target_feature))) == 1:\n",
        "            return DTNode(label=data.get(self.target_feature).iloc[0])\n",
        "\n",
        "        # otherwise, calculte the gini indices of all current features\n",
        "        feature_gini_indices = {}\n",
        "        feature_attr_set = {}\n",
        "\n",
        "        for feature_name in features:\n",
        "            attr_sets = self._get_feature_attr_sets(list(features[feature_name]))\n",
        "            for attr_set in attr_sets:\n",
        "                subset_data_left = pd.DataFrame()\n",
        "                for attr in attr_set[0]:\n",
        "                    subset_data_left = subset_data_left.append(data.loc[data[feature_name] == attr])\n",
        "\n",
        "                subset_data_right = pd.DataFrame()\n",
        "                for attr in attr_set[1]:\n",
        "                    subset_data_right = subset_data_right.append(data.loc[data[feature_name] == attr])\n",
        "\n",
        "                gini_index_left = self._get_gini_index(subset_data_left)\n",
        "                gini_index_right = self._get_gini_index(subset_data_right)\n",
        "\n",
        "                n1 = len(subset_data_left)\n",
        "                n2 = len(subset_data_right)\n",
        "                gini_index = (n1 / (n1 + n2)) * gini_index_left + (n2 / (n1 + n2)) * gini_index_right\n",
        "\n",
        "                if feature_name in feature_gini_indices:\n",
        "                    if feature_gini_indices[feature_name] > gini_index:\n",
        "                        feature_gini_indices[feature_name] = gini_index\n",
        "                        feature_attr_set[feature_name] = attr_set\n",
        "                else:\n",
        "                    feature_gini_indices[feature_name] = gini_index\n",
        "                    feature_attr_set[feature_name] = attr_set\n",
        "\n",
        "        # find the feature having minimum gini index\n",
        "        min_gini_index = 1\n",
        "        min_gini_index_feature = ''\n",
        "        min_gini_index_attr_set = []\n",
        "        for feature_name in feature_gini_indices:\n",
        "            if feature_gini_indices[feature_name] < min_gini_index:\n",
        "                min_gini_index = feature_gini_indices[feature_name]\n",
        "                min_gini_index_feature = feature_name\n",
        "                min_gini_index_attr_set = feature_attr_set[feature_name]\n",
        "\n",
        "        # distribute the data in two subtrees(lef & right according to the attributes used to make the decision in this node)\n",
        "\n",
        "        left_tree_data = pd.DataFrame()\n",
        "        for attr in min_gini_index_attr_set[0]:\n",
        "            left_tree_data = left_tree_data.append(data.loc[data[min_gini_index_feature] == attr])\n",
        "\n",
        "        right_tree_data = pd.DataFrame()\n",
        "        for attr in min_gini_index_attr_set[1]:\n",
        "            right_tree_data = right_tree_data.append(data.loc[data[min_gini_index_feature] == attr])\n",
        "\n",
        "        # get new set of features which won't contain the feature used to make prediction in this node\n",
        "        subtree_tree_features = features.copy()\n",
        "        del subtree_tree_features[min_gini_index_feature]\n",
        "  \n",
        "        # create an internal node with feature having minimum gini index and build tree recursively\n",
        "        node = DTNode(node_type='internal', label=None, gini_index=min_gini_index, feature_name=min_gini_index_feature,\n",
        "                      left_attr_collection=min_gini_index_attr_set[0],\n",
        "                      right_attr_collection=min_gini_index_attr_set[1])\n",
        "\n",
        "        node.left = self._build_tree(left_tree_data.copy(), subtree_tree_features.copy())\n",
        "        node.right = self._build_tree(right_tree_data.copy(), subtree_tree_features.copy())\n",
        "\n",
        "        return node\n",
        "\n",
        "    # get gini index of the given sample(data)\n",
        "    def _get_gini_index(self, data):\n",
        "        label_counts = {}\n",
        "\n",
        "        for label in data.get(self.target_feature):\n",
        "            if label in label_counts:\n",
        "                label_counts[label] += 1\n",
        "            else:\n",
        "                label_counts[label] = 1\n",
        "\n",
        "        sample_count = sum([label_counts[label] for label in label_counts])\n",
        "        probability_sqr_sum = sum([(label_counts[label] / sample_count) ** 2 for label in label_counts])\n",
        "\n",
        "        return 1 - probability_sqr_sum\n",
        "\n",
        "\n",
        "# load the data\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data.csv')\n",
        "\n",
        "# initialize the tree\n",
        "dt = DT(data, 'profit')\n",
        "\n",
        "# predict the class of a new record\n",
        "print(dt.predict({'price': 'low', 'maintenance': 'high', 'capacity': 5, 'airbag': 'no'}))\n"
      ]
    }
  ]
}